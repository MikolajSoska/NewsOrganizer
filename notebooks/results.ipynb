{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple, Dict, Iterator, Callable\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib.gridspec import GridSpec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "logs_path = Path('../data/saved/logs')\n",
    "save_path = Path('images/results')\n",
    "save_path.mkdir(parents=True, exist_ok=True)\n",
    "sns.set_theme()\n",
    "sns.set_palette('muted')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_log_identifier(log_path: Path) -> int:\n",
    "    filename = log_path.stem\n",
    "    identifier = filename.split('-')[-1]\n",
    "    return int(identifier)\n",
    "\n",
    "\n",
    "def iter_over_log_files(path_to_logs: Path) -> Iterator[str]:\n",
    "    for log_file in sorted(path_to_logs.glob('*-log-epoch-*.log'), key=get_log_identifier):\n",
    "        yield log_file\n",
    "\n",
    "\n",
    "def parse_training_loss(log_path: Path, activate_special: Callable[[str], bool], special_mode: bool) -> \\\n",
    "        Tuple[List[float], List[int], List[float], List[int], Dict[str, List[float]], float, int, Dict[str, float],\n",
    "              bool]:\n",
    "    steps_list = []\n",
    "    loss_list = []\n",
    "    special_steps = []\n",
    "    special_loss = []\n",
    "    val_loss = None\n",
    "    val_step = None\n",
    "    train_scores = defaultdict(list)\n",
    "    val_scores = {}\n",
    "    epoch = 0\n",
    "    iteration_max = 0\n",
    "    with open(log_path, 'r') as log_file:\n",
    "        for line in log_file:\n",
    "            if activate_special(line):\n",
    "                special_mode = True\n",
    "                continue\n",
    "\n",
    "            if 'ROUGE' in line or 'F1' in line:\n",
    "                line_split = line.split(', ')\n",
    "                if 'memory' in line: # Training scores\n",
    "                    for score in line_split[-4:-1]:\n",
    "                        score, value = score.split(': ')\n",
    "                        train_scores[score].append(float(value))\n",
    "                else: # Validation scores\n",
    "                    loss = line_split[2]\n",
    "                    val_loss = float(loss.replace('Loss: ', ''))\n",
    "                    val_step = (epoch + 1) * iteration_max\n",
    "                    for score in line_split[-3:]:\n",
    "                        score, value = score.split(': ')\n",
    "                        val_scores[score] = float(value)\n",
    "                    continue\n",
    "\n",
    "            if 'Loss' not in line:\n",
    "                continue\n",
    "            line_split = line.split(',')\n",
    "            step = line_split[0]\n",
    "            epoch, iteration = step.split(' Iter: ')\n",
    "            epoch = int(epoch.replace('Epoch: ', ''))\n",
    "            iteration, iteration_max = iteration.split('/')\n",
    "            iteration = int(iteration)\n",
    "            iteration_max = int(iteration_max)\n",
    "            loss = line_split[2].replace('Loss: ', '')\n",
    "            loss = float(loss)\n",
    "            if special_mode:\n",
    "                special_loss.append(loss)\n",
    "                special_steps.append(epoch * iteration_max + iteration)\n",
    "            else:\n",
    "                loss_list.append(loss)\n",
    "                steps_list.append(epoch * iteration_max + iteration)\n",
    "\n",
    "    return loss_list, steps_list, special_loss, special_steps, train_scores, val_loss, val_step, val_scores, \\\n",
    "           special_mode\n",
    "\n",
    "\n",
    "def parse_full_validation_summarization(log_path: Path) -> Tuple[List[float], Dict[str, List[float]]]:\n",
    "    scores = defaultdict(list)\n",
    "    loss_list = []\n",
    "    with open(log_path / f'{log_path.stem}-log-full_eval.log', 'r') as val_file:\n",
    "        for line in val_file:\n",
    "            if 'test phase' in line:\n",
    "                break\n",
    "\n",
    "            if 'ROUGE' not in line:\n",
    "                continue\n",
    "\n",
    "            line_split = line.split(', ')\n",
    "            loss = line_split[2]\n",
    "            val_loss = float(loss.replace('Loss: ', ''))\n",
    "            loss_list.append(val_loss)\n",
    "            for score in line_split[-3:]:\n",
    "                score, value = score.split(': ')\n",
    "                scores[score].append(float(value))\n",
    "\n",
    "    return loss_list, scores\n",
    "\n",
    "\n",
    "def get_model_performance(path: Path, activate_special: Callable[[str], bool] = lambda _: False,\n",
    "                                  use_full_validation: bool = False) -> \\\n",
    "        Tuple[List[float], List[int], List[float], List[int], Dict[str, List[float]], List[float], List[int],\n",
    "              Dict[str, List[float]]]:\n",
    "    special_mode = False\n",
    "    loss_all = []\n",
    "    steps_all = []\n",
    "    special_loss_all = []\n",
    "    special_steps_all = []\n",
    "    val_loss_all = []\n",
    "    val_steps_all = []\n",
    "    train_scores_all = defaultdict(list)\n",
    "    val_scores_all = defaultdict(list)\n",
    "    for log_file in iter_over_log_files(path):\n",
    "        loss, steps, special_loss, special_steps, train_scores, val_loss, val_steps, val_scores, special_mode = \\\n",
    "            parse_training_loss(log_file, activate_special, special_mode)\n",
    "        loss_all += loss\n",
    "        steps_all += steps\n",
    "        special_loss_all += special_loss\n",
    "        special_steps_all += special_steps\n",
    "        for score, value in train_scores.items():\n",
    "            train_scores_all[score] += value\n",
    "        val_loss_all.append(val_loss)\n",
    "        val_steps_all.append(val_steps)\n",
    "        for score, value in val_scores.items():\n",
    "            val_scores_all[score].append(value)\n",
    "\n",
    "    if use_full_validation:\n",
    "        val_loss_all, val_scores_all = parse_full_validation_summarization(path)\n",
    "\n",
    "    return loss_all, steps_all, special_loss_all, special_steps_all, train_scores_all, val_loss_all, val_steps_all, \\\n",
    "           val_scores_all"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def plot_pointer_generator_performance(path: Path, dataset: str, use_full_validation: bool = False) -> None:\n",
    "    train_loss, train_steps, coverage_loss, coverage_steps, _, val_loss, val_steps, scores = \\\n",
    "        get_model_performance(path, activate_special=lambda line: 'coverage' in line,\n",
    "                              use_full_validation=use_full_validation)\n",
    "    fig = plt.figure(figsize=(15, 10))\n",
    "    grid = GridSpec(2, 2)\n",
    "    train_ax: plt.Axes = plt.subplot(grid[0, :])\n",
    "    val_ax: plt.Axes = plt.subplot(grid[1, 0])\n",
    "    test_ax: plt.Axes = plt.subplot(grid[1, 1])\n",
    "\n",
    "    train_type = ['Normal training' for _ in train_steps] + ['Training with coverage' for _ in coverage_steps]\n",
    "    train_data = pd.DataFrame(\n",
    "        {'Iteration': train_steps + coverage_steps, 'Loss': train_loss + coverage_loss, 'Training type': train_type}\n",
    "    )\n",
    "    val_data = {\n",
    "        'Iteration': val_steps,\n",
    "        'Loss': val_loss\n",
    "    }\n",
    "    test_data = pd.DataFrame(scores)\n",
    "    test_data['Iteration'] = val_steps\n",
    "    test_data = test_data.set_index('Iteration')\n",
    "\n",
    "    train_ax.axvline(x=coverage_steps[0], lw=1, ls='--', c='b', alpha=0.5)\n",
    "    sns.lineplot(data=train_data, x='Iteration', y='Loss', hue='Training type', ax=train_ax)\n",
    "    sns.lineplot(data=val_data, x='Iteration', y='Loss', ax=val_ax, color='g')\n",
    "    sns.lineplot(data=test_data, ax=test_ax)\n",
    "\n",
    "    fig.suptitle(f'Pointer generator performance on {dataset} dataset.')\n",
    "    train_ax.set_title('Loss change during training')\n",
    "    val_ax.set_title('Validation loss change during training')\n",
    "    test_ax.set_title('ROUGE scores change during training')\n",
    "\n",
    "    plot_title = dataset.replace(' ', '_').replace('/', '_').lower()\n",
    "    plt.savefig(f'images/results/pointer_generator_{plot_title}.png')\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def plot_transformer_performance(path: Path, dataset: str, use_full_validation: bool = False) -> None:\n",
    "    train_loss, train_steps, _, _, _, val_loss, val_steps, scores = \\\n",
    "        get_model_performance(path, use_full_validation=use_full_validation)\n",
    "    fig = plt.figure(figsize=(15, 10))\n",
    "    grid = GridSpec(2, 2)\n",
    "    train_ax: plt.Axes = plt.subplot(grid[0, :])\n",
    "    val_ax: plt.Axes = plt.subplot(grid[1, 0])\n",
    "    test_ax: plt.Axes = plt.subplot(grid[1, 1])\n",
    "\n",
    "    train_data = {\n",
    "        'Iteration': train_steps,\n",
    "        'Loss': train_loss\n",
    "    }\n",
    "    val_data = {\n",
    "        'Iteration': val_steps,\n",
    "        'Loss': val_loss\n",
    "    }\n",
    "    test_data = pd.DataFrame(scores)\n",
    "    test_data['Iteration'] = val_steps\n",
    "    test_data = test_data.set_index('Iteration')\n",
    "\n",
    "    sns.lineplot(data=train_data, x='Iteration', y='Loss', ax=train_ax)\n",
    "    sns.lineplot(data=val_data, x='Iteration', y='Loss', ax=val_ax, color='g')\n",
    "    sns.lineplot(data=test_data, ax=test_ax)\n",
    "\n",
    "    fig.suptitle(f'Transformer performance on {dataset} dataset.')\n",
    "    train_ax.set_title('Loss change during training')\n",
    "    val_ax.set_title('Validation loss change during training')\n",
    "    test_ax.set_title('ROUGE scores change during training')\n",
    "\n",
    "    plot_subtitle = dataset.replace(' ', '_').replace('/', '_').lower()\n",
    "    plt.savefig(f'images/results/transformer_{plot_subtitle}.png')\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def plot_rl_performance(path: Path, dataset: str, use_full_validation: bool = False) -> None:\n",
    "    pretrain_loss, pretrain_steps, train_loss, train_steps, _, val_loss, val_steps, scores = \\\n",
    "        get_model_performance(path, activate_special=lambda line: 'pretraining' in line,\n",
    "                                      use_full_validation=use_full_validation)\n",
    "    fig = plt.figure(figsize=(15, 10))\n",
    "    grid = GridSpec(2, 2)\n",
    "    pretrain_ax: plt.Axes = plt.subplot(grid[0, 0])\n",
    "    train_ax: plt.Axes = plt.subplot(grid[0, 1])\n",
    "    val_ax: plt.Axes = plt.subplot(grid[1, 0])\n",
    "    test_ax: plt.Axes = plt.subplot(grid[1, 1])\n",
    "\n",
    "    pretrain_data = {\n",
    "        'Iteration': pretrain_steps,\n",
    "        'Loss': pretrain_loss\n",
    "    }\n",
    "    train_data = {\n",
    "        'Iteration': train_steps,\n",
    "        'Loss': train_loss\n",
    "    }\n",
    "    val_data = {\n",
    "        'Iteration': val_steps,\n",
    "        'Loss': val_loss\n",
    "    }\n",
    "    test_data = pd.DataFrame(scores)\n",
    "    test_data['Iteration'] = val_steps\n",
    "    test_data = test_data.set_index('Iteration')\n",
    "\n",
    "    sns.lineplot(data=pretrain_data, x='Iteration', y='Loss', ax=pretrain_ax)\n",
    "    sns.lineplot(data=train_data, x='Iteration', y='Loss', ax=train_ax, color='r')\n",
    "    sns.lineplot(data=val_data, x='Iteration', y='Loss', ax=val_ax, color='g')\n",
    "    sns.lineplot(data=test_data, ax=test_ax)\n",
    "\n",
    "    fig.suptitle(f'RL model performance on {dataset} dataset.')\n",
    "    train_ax.set_title('Loss change during pretraining')\n",
    "    train_ax.set_title('Loss change during training (fine-tuning)')\n",
    "    val_ax.set_title('Validation loss change during training')\n",
    "    test_ax.set_title('ROUGE scores change during training')\n",
    "\n",
    "    plot_subtitle = dataset.replace(' ', '_').replace('/', '_').lower()\n",
    "    plt.savefig(f'images/results/rl_{plot_subtitle}.png')\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def plot_ner_performance(path: Path, model: str, dataset: str) -> None:\n",
    "    train_loss, train_steps, _, _, train_scores, val_loss, val_steps, val_scores = get_model_performance(path)\n",
    "    fig, (loss_ax, scores_ax) = plt.subplots(2, 1, figsize=(12, 10))\n",
    "    scores_ax: plt.Axes\n",
    "\n",
    "    phases = ['Training' for _ in train_steps] + ['Validation' for _ in val_steps]\n",
    "    loss_data = pd.DataFrame(\n",
    "        {'Iteration': train_steps + val_steps, 'Loss': train_loss + val_loss, 'Phase': phases}\n",
    "    )\n",
    "    scores_data = pd.DataFrame(\n",
    "        {\n",
    "            'Iteration': (train_steps + val_steps) * 3,\n",
    "            'Value': train_scores['F1'] + val_scores['F1'] + train_scores['Precision'] + val_scores['Precision'] +\n",
    "                     train_scores['Recall'] + val_scores['Recall'],\n",
    "            'Score': ['F1' for _ in train_steps + val_steps] + ['Precision' for _ in train_steps + val_steps] +\n",
    "                     ['Recall' for _ in train_steps + val_steps],\n",
    "            'Phase': phases * 3\n",
    "        }\n",
    "    )\n",
    "\n",
    "    sns.lineplot(data=loss_data, x='Iteration', y='Loss', hue='Phase', ax=loss_ax)\n",
    "    sns.lineplot(data=scores_data, x='Iteration', y='Value', hue='Score', style='Phase', ax=scores_ax)\n",
    "\n",
    "    fig.suptitle(f'{model} performance on {dataset} dataset.')\n",
    "    loss_ax.set_title('Loss change during training and validation')\n",
    "    loss_ax.set_title('Scores change during training and validation')\n",
    "\n",
    "    dataset_subtitle = dataset.replace(' ', '_').replace('/', '_').lower()\n",
    "    model_subtitle = model.replace('-', '_').replace(' ', '_').lower()\n",
    "    plt.savefig(f'images/results/{model_subtitle}_{dataset_subtitle}.png')\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_pointer_generator_performance(logs_path / 'pointer_generator', 'CNN/Daily Mail')\n",
    "plot_pointer_generator_performance(logs_path / 'pointer_generator-xsum', 'XSum', use_full_validation=True)\n",
    "plot_transformer_performance(logs_path / 'transformer', 'CNN/Daily Mail')\n",
    "plot_transformer_performance(logs_path / 'transformer', 'XSum')\n",
    "plot_rl_performance(logs_path / 'reinforcement_learning', 'CNN/Daily Mail', use_full_validation=True)\n",
    "plot_rl_performance(logs_path / 'reinforcement_learning-xsum', 'XSum', use_full_validation=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_ner_performance(logs_path / 'bilstm_cnn', 'BiLSTM-CNN', 'CoNLL-2003')\n",
    "plot_ner_performance(logs_path / 'bilstm_cnn-gmb', 'BiLSTM-CNN', 'GMB')\n",
    "plot_ner_performance(logs_path / 'bilstm_crf', 'BiLSTM-CRF', 'CoNLL-2003')\n",
    "plot_ner_performance(logs_path / 'bilstm_crf-gmb', 'BiLSTM-CRF', 'GMB')\n",
    "plot_ner_performance(logs_path / 'id_cnn', 'ID-CNN', 'CoNLL-2003')\n",
    "plot_ner_performance(logs_path / 'id_cnn-gmb', 'ID-CNN', 'GMB')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}