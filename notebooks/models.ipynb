{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import heapq\n",
    "from collections import defaultdict\n",
    "from importlib import import_module\n",
    "from pathlib import Path\n",
    "from typing import Any, Callable, List, Tuple, Dict\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import Tensor\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import neural.common.utils as utils\n",
    "from neural.common.data.vocab import Vocab, VocabBuilder\n",
    "from neural.common.scores import ROUGE, F1Score\n",
    "from neural.ner.dataloader import NERDataset, NERDataLoader\n",
    "from neural.summarization.dataloader import SummarizationDataset, SummarizationDataLoader\n",
    "from utils.database import DatabaseConnector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "models_path = Path('../data/saved/models')\n",
    "device = utils.get_device(use_cuda=True)\n",
    "utils.set_random_seed(0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def load_trained_model(model_id: str, path_to_model: Path, weights_name: str = None, **params: Any) -> nn.Module:\n",
    "    module = import_module(f'neural.train_{model_id}')\n",
    "    args = utils.load_args_from_file(path_to_model)\n",
    "    model_name = path_to_model.stem\n",
    "    weights_path = path_to_model / f'{model_name}.pt'\n",
    "\n",
    "    model = module.create_model_from_args(args, **params)\n",
    "    weights = torch.load(weights_path, map_location=device)\n",
    "    weights_name = weights_name or model_name\n",
    "    model.load_state_dict(weights[f'{weights_name}_state_dict'])\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    del weights\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def count_model_parameters(model: nn.Module) -> None:\n",
    "    learnable_parameters = defaultdict(int)\n",
    "    constant_parameters = defaultdict(int)\n",
    "    model.train()\n",
    "    for name, parameter in model.named_parameters():\n",
    "        parameter_name = name.split('.weight')[0].split('.bias')[0]\n",
    "        if parameter.requires_grad:\n",
    "            learnable_parameters[parameter_name] += torch.numel(parameter)\n",
    "        else:\n",
    "            constant_parameters[parameter_name] += torch.numel(parameter)\n",
    "    model.eval()\n",
    "\n",
    "    if len(learnable_parameters) > 0:\n",
    "        print('Learnable parameters:')\n",
    "        for name, count in learnable_parameters.items():\n",
    "            print(f'{name}: {count}')\n",
    "        print(f'Sum: {sum(learnable_parameters.values())}')\n",
    "\n",
    "    if len(constant_parameters) > 0:\n",
    "        print('Constant parameters:')\n",
    "        for name, count in constant_parameters.items():\n",
    "            print(f'{name}: {count}')\n",
    "        print(f'Sum: {sum(constant_parameters.values())}')\n",
    "\n",
    "\n",
    "def show_examples_summarization(model: nn.Module, loader: SummarizationDataLoader, vocab: Vocab,\n",
    "                                predict_tokens: Callable[[nn.Module, Tuple[Any, ...]], Tensor],\n",
    "                                use_oov: bool = True, examples_number: int = 3) -> None:\n",
    "    scorer = ROUGE(vocab, 'rouge1')\n",
    "    examples = []\n",
    "    with torch.no_grad():\n",
    "        for inputs in tqdm(loader):\n",
    "            inputs = utils.convert_input_to_device(inputs, device)\n",
    "            if use_oov:\n",
    "                targets, oov_list = inputs[-2:]\n",
    "            else:\n",
    "                oov_list = None\n",
    "                targets = inputs[-1]\n",
    "\n",
    "            tokens = predict_tokens(model, inputs)\n",
    "            for i in range(tokens.shape[1]):\n",
    "                if use_oov:\n",
    "                    utils.add_words_to_vocab(vocab, oov_list[i])\n",
    "\n",
    "                score_out = tokens[:, i].unsqueeze(dim=1)\n",
    "                score_target = targets[:, i].unsqueeze(dim=1)\n",
    "                score = scorer.score(score_out, score_target)\n",
    "\n",
    "                score_out = utils.clean_predicted_tokens(score_out, 3)\n",
    "                score_out = utils.remove_unnecessary_padding(score_out)\n",
    "                score_out = utils.tensor_to_string(vocab, score_out)\n",
    "                score_target = utils.remove_unnecessary_padding(score_target)\n",
    "                score_target = utils.tensor_to_string(vocab, score_target)\n",
    "\n",
    "                if use_oov:\n",
    "                    utils.remove_words_from_vocab(vocab, oov_list[i])\n",
    "                heapq.heappush(examples, (score['ROUGE-1'], (score_out, score_target)))\n",
    "\n",
    "    print_summarization_examples(examples, examples_number, best=True)\n",
    "    print_summarization_examples(examples, examples_number, best=False)\n",
    "\n",
    "\n",
    "def print_summarization_examples(examples: List[Tuple[float, Tuple[str, str]]], examples_number: int,\n",
    "                                 best: bool) -> None:\n",
    "    if best:\n",
    "        examples_type = 'Best'\n",
    "        examples_generator = heapq.nlargest\n",
    "    else:\n",
    "        examples_type = 'Worst'\n",
    "        examples_generator = heapq.nsmallest\n",
    "\n",
    "    print(f'{examples_type} examples:')\n",
    "    for score, (prediction, target) in examples_generator(examples_number, examples):\n",
    "        print('ROUGE-1:', score)\n",
    "        print('Prediction:', prediction)\n",
    "        print()\n",
    "        print('Target:', target)\n",
    "        print(50 * '-')\n",
    "\n",
    "\n",
    "def predict_pointer_generator(model: nn.Module, inputs: Tuple[Any, ...]) -> Tensor:\n",
    "    texts, texts_lengths, summaries, summaries_lengths, texts_extended, targets, oov_list = inputs\n",
    "    oov_size = len(max(oov_list, key=lambda x: len(x)))\n",
    "    _, tokens, _, _ = model(texts, texts_lengths, texts_extended, oov_size)\n",
    "\n",
    "    return tokens\n",
    "\n",
    "\n",
    "def predict_rl(model: nn.Module, inputs: Tuple[Any, ...]) -> Tensor:\n",
    "    texts, texts_lengths, summaries, summaries_lengths, texts_extended, targets, oov_list = inputs\n",
    "    oov_size = len(max(oov_list, key=lambda x: len(x)))\n",
    "    _, tokens, _ = model(texts, texts_lengths, texts_extended, oov_size)\n",
    "\n",
    "    return tokens\n",
    "\n",
    "\n",
    "def predict_transformer(model: nn.Module, inputs: Tuple[Any, ...]) -> Tensor:\n",
    "    texts, _, summaries, _, targets = inputs\n",
    "    _, tokens = model(texts)\n",
    "\n",
    "    return tokens\n",
    "\n",
    "\n",
    "def show_examples_ner(model: nn.Module, loader: NERDataLoader, vocab: Vocab, tags_dict: Dict[int, Tuple[str, str]],\n",
    "                      predict_tokens: Callable[[nn.Module, Tuple[Any, ...]], Tensor], examples_number: int = 3) -> None:\n",
    "    labels = list(tags_dict.keys())\n",
    "    scorer = F1Score(labels)\n",
    "    examples = []\n",
    "    with torch.no_grad():\n",
    "        for inputs in tqdm(loader):\n",
    "            inputs = utils.convert_input_to_device(inputs, device)\n",
    "            text, targets = inputs[:2]\n",
    "            tokens = predict_tokens(model, inputs)\n",
    "            for i in range(tokens.shape[1]):\n",
    "                score_out = tokens[:, i].unsqueeze(dim=1)\n",
    "                score_target = targets[:, i].unsqueeze(dim=1)\n",
    "\n",
    "                score_out = score_out[score_target >= 0]\n",
    "                score_target = score_target[score_target >= 0]\n",
    "                if not any(score_target) != 0:\n",
    "                    continue\n",
    "\n",
    "                score = scorer.score(score_out, score_target)\n",
    "\n",
    "                texts = text[:, i]\n",
    "                texts = texts[texts > 0]\n",
    "\n",
    "                score_out = ' '.join(tags_dict[tag.item()][0] if tag.item() in tags_dict else 'O' for tag in score_out)\n",
    "                score_target = ' '.join(tags_dict[tag.item()][0] if tag.item() in tags_dict else 'O' for tag\n",
    "                                        in score_target)\n",
    "                texts = utils.tensor_to_string(vocab, texts)\n",
    "\n",
    "                heapq.heappush(examples, (score['F1'], (texts, score_out, score_target)))\n",
    "\n",
    "    print_ner_examples(examples, examples_number, best=True)\n",
    "    print_ner_examples(examples, examples_number, best=False)\n",
    "\n",
    "\n",
    "def print_ner_examples(examples: List[Tuple[float, Tuple[str, str]]], examples_number: int,\n",
    "                       best: bool) -> None:\n",
    "    if best:\n",
    "        examples_type = 'Best'\n",
    "        examples_generator = heapq.nlargest\n",
    "    else:\n",
    "        examples_type = 'Worst'\n",
    "        examples_generator = heapq.nsmallest\n",
    "\n",
    "    print(f'{examples_type} examples:')\n",
    "    for score, (text, prediction, target) in examples_generator(examples_number, examples):\n",
    "        print('F1:', score)\n",
    "        print('Text:', text)\n",
    "        print('Prediction:', prediction)\n",
    "        print('Target:', target)\n",
    "        print(50 * '-')\n",
    "\n",
    "\n",
    "def predict_bilstm_cnn(model: nn.Module, inputs: Tuple[Any, ...]) -> Tensor:\n",
    "    words, tags, chars, word_features, char_features = inputs\n",
    "    output = model(words, chars, word_features, char_features)\n",
    "    tokens = torch.argmax(output, dim=-1)\n",
    "\n",
    "    return tokens\n",
    "\n",
    "\n",
    "def predict_bilstm_crf(model: nn.Module, inputs: Tuple[Any, ...]) -> Tensor:\n",
    "    words, tags, chars, _, _ = inputs\n",
    "    mask = (tags >= 0).float()\n",
    "    loss, predictions = model(words, chars, tags, mask)\n",
    "\n",
    "    return predictions\n",
    "\n",
    "\n",
    "def predict_id_cnn(model: nn.Module, inputs: Tuple[Any, ...]) -> Tensor:\n",
    "    words, tags, _, word_features, _ = inputs\n",
    "    outputs = model(words, word_features)\n",
    "    tokens = torch.argmax(outputs[-1], dim=-1)\n",
    "\n",
    "    return tokens\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pointer_generator = load_trained_model('pointer_generator', models_path / 'pointer_generator', bos_index=2, eos_index=3,\n",
    "                                       unk_index=1)\n",
    "pointer_generator.activate_coverage()\n",
    "count_model_parameters(pointer_generator)\n",
    "vocab = VocabBuilder.build_vocab('cnn_dailymail', 'summarization', vocab_size=50000)\n",
    "dataset = SummarizationDataset('cnn_dailymail', 'test', 400, 100, vocab, get_oov=True)\n",
    "dataloader = SummarizationDataLoader(dataset, batch_size=32)\n",
    "show_examples_summarization(pointer_generator, dataloader, vocab, predict_pointer_generator)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "reinforcement_summarization = load_trained_model('rl', models_path / 'reinforcement_learning', weights_name='rl_model',\n",
    "                                                 bos_index=2, eos_index=3, unk_index=1)\n",
    "count_model_parameters(reinforcement_summarization)\n",
    "vocab = VocabBuilder.build_vocab('cnn_dailymail', 'summarization', vocab_size=50000)\n",
    "dataset = SummarizationDataset('cnn_dailymail', 'test', 800, 100, vocab, get_oov=True)\n",
    "dataloader = SummarizationDataLoader(dataset, batch_size=32)\n",
    "show_examples_summarization(reinforcement_summarization, dataloader, vocab, predict_rl)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "transformer = load_trained_model('transformer', models_path / 'transformer', bos_index=2, eos_index=3)\n",
    "count_model_parameters(transformer)\n",
    "vocab = VocabBuilder.build_vocab('cnn_dailymail', 'summarization', vocab_size=50000)\n",
    "dataset = SummarizationDataset('cnn_dailymail', 'test', 400, 100, vocab)\n",
    "dataloader = SummarizationDataLoader(dataset, batch_size=16)\n",
    "show_examples_summarization(transformer, dataloader, vocab, predict_transformer, use_oov=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tags_count = DatabaseConnector().get_tag_count('conll2003') + 1\n",
    "tags_dict = DatabaseConnector().get_tags_dict('conll2003')\n",
    "vocab = VocabBuilder.build_vocab('conll2003', 'ner', vocab_type='char', digits_to_zero=True)\n",
    "bilstm_cnn = load_trained_model('bilstm_cnn', models_path / 'bilstm_cnn', tags_count=tags_count, vocab=vocab)\n",
    "count_model_parameters(bilstm_cnn)\n",
    "dataset = NERDataset('conll2003', 'test', vocab)\n",
    "dataloader = NERDataLoader(dataset, batch_size=128, two_sided_char_padding=True, conv_kernel_size=3)\n",
    "show_examples_ner(bilstm_cnn, dataloader, vocab, tags_dict, predict_bilstm_cnn)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tags_count = DatabaseConnector().get_tag_count('conll2003') + 1\n",
    "tags_dict = DatabaseConnector().get_tags_dict('conll2003')\n",
    "vocab = VocabBuilder.build_vocab('conll2003', 'ner', vocab_type='char', digits_to_zero=True)\n",
    "bilstm_crf = load_trained_model('bilstm_crf', models_path / 'bilstm_crf', tags_count=tags_count, vocab=vocab)\n",
    "count_model_parameters(bilstm_crf)\n",
    "dataset = NERDataset('conll2003', 'test', vocab)\n",
    "dataloader = NERDataLoader(dataset, batch_size=128)\n",
    "show_examples_ner(bilstm_crf, dataloader, vocab, tags_dict, predict_bilstm_crf)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tags_count = DatabaseConnector().get_tag_count('conll2003') + 1\n",
    "tags_dict = DatabaseConnector().get_tags_dict('conll2003')\n",
    "vocab = VocabBuilder.build_vocab('conll2003', 'ner', vocab_type='char', digits_to_zero=True)\n",
    "id_cnn = load_trained_model('id_cnn', models_path / 'id_cnn', tags_count=tags_count, vocab=vocab)\n",
    "count_model_parameters(id_cnn)\n",
    "dataset = NERDataset('conll2003', 'test', vocab)\n",
    "dataloader = NERDataLoader(dataset, batch_size=128)\n",
    "show_examples_ner(id_cnn, dataloader, vocab, tags_dict, predict_id_cnn)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}